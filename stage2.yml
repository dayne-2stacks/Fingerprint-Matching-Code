train:
  start_epoch: 60         # Set to a positive integer to resume from a checkpoint
  num_iterations: 25    # Iterations per epoch
  BATCH_SIZE: 1
  K_Optimize: true       # Whether to optimize k (AFA) modules separately
  K_LOSS: true          # Whether to use k_loss as the primary metric for early stopping
  LR: 1.e-20              # Learning rate for main network (joint training)
  BACKBONE_LR: 1.e-20      # Learning rate for backbone parameters
  K_LR: 1.e-6             # Learning rate for k-regression (AFA) modules
  LR_DECAY: 0.5          # LR decay factor
  patience: 25            # Early stopping patience (in epochs)
  num_epochs: 200

ngm:
  REGRESSION: true       # If true, use predicted k in stage 3; otherwise, use ground truth k
